{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbdc7b51",
   "metadata": {},
   "source": [
    "# The jupyter notebook is intended to generate syntheticdata using Synthetic Data Vault. \n",
    "\n",
    "1. Generate using the hyper parameters at the bare minimum \n",
    "    a. use the hyper parameters epoch and batch size for the GAN\n",
    "2. The dataset size equal to that of the original dataset it the size is less than 2000\n",
    "3. Start sampling at the size of 2000, 5000, 1000 and maximum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16bcfc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') # ignore any warnings \n",
    "\n",
    "import pandas as pd\n",
    "from sdv.tabular import GaussianCopula\n",
    "from sdv.tabular import CTGAN\n",
    "from sdv.tabular import CopulaGAN\n",
    "from sdv.tabular import TVAE\n",
    "from util.dataloader import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3aaef174",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_gaussian(in_file):\n",
    "    start_time = time.strftime(\"%H:%M:%S\", time.localtime())\n",
    "    gaussian_model = GaussianCopula()\n",
    "    gaussian_model.fit(real_df)\n",
    "    gaus_synthetic_df = gaussian_model.sample(SAMPLE_SIZE)\n",
    "    gaus_synthetic_df.to_csv(out_path1)\n",
    "    end_time = time.strftime(\"%H:%M:%S\", time.localtime())\n",
    "    print('Total processing time for gaussian_synthesizer '+in_file+ ' is : {:.5f}'.format(elapsedtime(start_time, end_time))+ \" minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "762925e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ctgan(in_file):\n",
    "    start_time = time.strftime(\"%H:%M:%S\", time.localtime())\n",
    "    ctgan = CTGAN(batch_size = BATCH_SIZE, epochs = EPOCH)\n",
    "    ctgan.fit(real_df)\n",
    "    ctgan_synthetic_df = ctgan.sample(SAMPLE_SIZE)\n",
    "    ctgan_synthetic_df.to_csv(out_path2)\n",
    "    end_time = time.strftime(\"%H:%M:%S\", time.localtime())\n",
    "    print('Total processing time for ctgan_synthesizer '+in_file+ ' is : {:.5f}'.format(elapsedtime(start_time, end_time))+ \" minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abfeee7f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad85ed22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_copula_gan(in_file):\n",
    "    start_time = time.strftime(\"%H:%M:%S\", time.localtime())\n",
    "    copula_gan_model = CopulaGAN(epochs=EPOCH,\n",
    "                batch_size=BATCH_SIZE,\n",
    "                generator_dim=(128, 128, 128),\n",
    "                discriminator_dim=(128, 128, 128))\n",
    "    copula_gan_model.fit(real_df)\n",
    "    cgan_synthetic_df = copula_gan_model.sample(SAMPLE_SIZE)\n",
    "    cgan_synthetic_df.to_csv(out_path3)\n",
    "    end_time = time.strftime(\"%H:%M:%S\", time.localtime())\n",
    "    '{:.5f}'.format\n",
    "    print('Total processing time for cgan_synthesizer '+in_file+ ' is : {:.5f}'.format(elapsedtime(start_time, end_time))+ \" minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7aac11ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tvae(in_file):    \n",
    "    start_time = time.strftime(\"%H:%M:%S\", time.localtime())\n",
    "    tvae_model = TVAE(epochs=EPOCH,\n",
    "                batch_size=BATCH_SIZE)\n",
    "    tvae_model.fit(real_df)\n",
    "    tvae_synthetic_df = tvae_model.sample(SAMPLE_SIZE)\n",
    "    tvae_synthetic_df.to_csv(out_path4)\n",
    "    end_time = time.strftime(\"%H:%M:%S\", time.localtime())\n",
    "    print('Total processing time for tvae_synthesizer '+in_file+ ' is : {:.5f}'.format(elapsedtime(start_time, end_time))+ \" minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defb90fd",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "574560f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_census_data():\n",
    "    #path1, path2, path3 = ''\n",
    "    path1 = '../Real Datasets/Adult Census Income Dataset/adult.csv'\n",
    "    path2 = '../Real Datasets/Adult Census Income Dataset/test.csv'\n",
    "    real1 = pd.read_csv(path1)\n",
    "    real2 = pd.read_csv(path2)\n",
    "    real2_no_header = real2[1:] \n",
    "    real = real1.append(real2_no_header)\n",
    "    real.to_csv('../Real Datasets/Adult Census Income Dataset/census.csv')\n",
    "\n",
    "def concat_anomaly_data():\n",
    "    #path1, path2, path3 = ''\n",
    "    path1 = '../Real Datasets/Anomaly Detection/Participants_Data_WH18/Train.csv'\n",
    "    path2 = '../Real Datasets/Anomaly Detection/Participants_Data_WH18/Test.csv'\n",
    "    path3 = '../Real Datasets/Anomaly Detection/Participants_Data_WH18/Sample_submission.csv'\n",
    "\n",
    "    # Read 3 files in the package separtely\n",
    "#    real1 = pd.read_csv(path1, header=0)\n",
    "#    real2 = pd.read_csv(path2, header=0)\n",
    "#    real3 = pd.read_csv(path3, header=0)\n",
    "    \n",
    "    # Read 3 files in the package separtely\n",
    "    real1 = pd.read_csv(path1)\n",
    "    real2 = pd.read_csv(path2)\n",
    "    real3 = pd.read_csv(path3)\n",
    "\n",
    "    # merge the sample submision with test data\n",
    "    df_list = [real2, real3]\n",
    "    test_df = pd.concat(df_list, axis=1)\n",
    "\n",
    "    #append the concatenated test datset with train dataset. Remove the header from the test set \n",
    "    #test_no_header = test_df[1:] \n",
    "    real = real1.append(test_df)\n",
    "    real.to_csv('../Real Datasets/Anomaly Detection/Participants_Data_WH18/anomaly.csv')\n",
    "\n",
    "# Cancer data file has some of the values as '?' which is to be cleaned. Else, the generator fails\n",
    "def get_cervical_cancer_data():\n",
    "    path = ''\n",
    "    path = '../Real Datasets/Cervical Cancer/risk_factors_cervical_cancer.csv'\n",
    "    real = pd.read_csv(path) # in datasets/\n",
    "    real.replace('?', 0, inplace=True)\n",
    "    real.drop(['STDs: Time since first diagnosis', 'STDs: Time since last diagnosis'], axis=1, inplace=True )\n",
    "    real.to_csv('../Real Datasets/Cervical Cancer/cervical_cancer.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b93f395e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total processing time for gaussian_synthesizer Titanic is : 0.05000 minutes\n",
      "Total processing time for ctgan_synthesizer Titanic is : 1.40000 minutes\n",
      "Total processing time for cgan_synthesizer Titanic is : 0.93333 minutes\n",
      "Total processing time for tvae_synthesizer Titanic is : 0.16667 minutes\n",
      "Total processing time for gaussian_synthesizer insurance is : 0.03333 minutes\n",
      "Total processing time for ctgan_synthesizer insurance is : 0.13333 minutes\n",
      "Total processing time for cgan_synthesizer insurance is : 0.13333 minutes\n",
      "Total processing time for tvae_synthesizer insurance is : 0.06667 minutes\n",
      "Total processing time for gaussian_synthesizer House_Rent_Dataset is : 0.11667 minutes\n",
      "Total processing time for ctgan_synthesizer House_Rent_Dataset is : 16.93333 minutes\n",
      "Total processing time for cgan_synthesizer House_Rent_Dataset is : 10.56667 minutes\n",
      "Total processing time for tvae_synthesizer House_Rent_Dataset is : 0.51667 minutes\n",
      "Total processing time for gaussian_synthesizer Card_Application_Data is : 0.61667 minutes\n",
      "Total processing time for ctgan_synthesizer Card_Application_Data is : 4.36667 minutes\n",
      "Total processing time for cgan_synthesizer Card_Application_Data is : 5.01667 minutes\n",
      "Total processing time for tvae_synthesizer Card_Application_Data is : 1.50000 minutes\n",
      "Total processing time for gaussian_synthesizer creditcard is : 11.76667 minutes\n",
      "Total processing time for ctgan_synthesizer creditcard is : 106.01667 minutes\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [18]\u001b[0m, in \u001b[0;36m<cell line: 22>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     50\u001b[0m generate_gaussian(in_file[i])\n\u001b[0;32m     51\u001b[0m generate_ctgan(in_file[i])\n\u001b[1;32m---> 52\u001b[0m \u001b[43mgenerate_copula_gan\u001b[49m\u001b[43m(\u001b[49m\u001b[43min_file\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     53\u001b[0m generate_tvae(in_file[i])\n",
      "Input \u001b[1;32mIn [14]\u001b[0m, in \u001b[0;36mgenerate_copula_gan\u001b[1;34m(in_file)\u001b[0m\n\u001b[0;32m      2\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m\"\u001b[39m, time\u001b[38;5;241m.\u001b[39mlocaltime())\n\u001b[0;32m      3\u001b[0m copula_gan_model \u001b[38;5;241m=\u001b[39m CopulaGAN(epochs\u001b[38;5;241m=\u001b[39mEPOCH,\n\u001b[0;32m      4\u001b[0m             batch_size\u001b[38;5;241m=\u001b[39mBATCH_SIZE,\n\u001b[0;32m      5\u001b[0m             generator_dim\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m128\u001b[39m),\n\u001b[0;32m      6\u001b[0m             discriminator_dim\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m128\u001b[39m))\n\u001b[1;32m----> 7\u001b[0m \u001b[43mcopula_gan_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreal_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m cgan_synthetic_df \u001b[38;5;241m=\u001b[39m copula_gan_model\u001b[38;5;241m.\u001b[39msample(SAMPLE_SIZE)\n\u001b[0;32m      9\u001b[0m cgan_synthetic_df\u001b[38;5;241m.\u001b[39mto_csv(out_path3)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\syntheticdata\\lib\\site-packages\\sdv\\tabular\\base.py:149\u001b[0m, in \u001b[0;36mBaseTabularModel.fit\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\u001b[38;5;241m.\u001b[39mget_dtypes(ids\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    147\u001b[0m     LOGGER\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[0;32m    148\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m model to table \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m--> 149\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransformed\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\syntheticdata\\lib\\site-packages\\sdv\\tabular\\copulagan.py:205\u001b[0m, in \u001b[0;36mCopulaGAN._fit\u001b[1;34m(self, table_data)\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hyper_transformer \u001b[38;5;241m=\u001b[39m HyperTransformer()\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hyper_transformer\u001b[38;5;241m.\u001b[39mset_config({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtransformers\u001b[39m\u001b[38;5;124m'\u001b[39m: transformers, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msdtypes\u001b[39m\u001b[38;5;124m'\u001b[39m: sdtypes})\n\u001b[1;32m--> 205\u001b[0m table_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_hyper_transformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtable_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtransformers\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m_fit(table_data)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\syntheticdata\\lib\\site-packages\\rdt\\hyper_transformer.py:792\u001b[0m, in \u001b[0;36mHyperTransformer.fit_transform\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    781\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit_transform\u001b[39m(\u001b[38;5;28mself\u001b[39m, data):\n\u001b[0;32m    782\u001b[0m     \u001b[38;5;124;03m\"\"\"Fit the transformers to the data and then transform it.\u001b[39;00m\n\u001b[0;32m    783\u001b[0m \n\u001b[0;32m    784\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    790\u001b[0m \u001b[38;5;124;03m            Transformed data.\u001b[39;00m\n\u001b[0;32m    791\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 792\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    793\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(data)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\syntheticdata\\lib\\site-packages\\rdt\\hyper_transformer.py:719\u001b[0m, in \u001b[0;36mHyperTransformer.fit\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    717\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_columns \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(data\u001b[38;5;241m.\u001b[39mcolumns)\n\u001b[0;32m    718\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m field \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_columns:\n\u001b[1;32m--> 719\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_field_transformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfield\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfield_transformers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfield\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    721\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_all_fields_fitted()\n\u001b[0;32m    722\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fitted \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\syntheticdata\\lib\\site-packages\\rdt\\hyper_transformer.py:654\u001b[0m, in \u001b[0;36mHyperTransformer._fit_field_transformer\u001b[1;34m(self, data, field, transformer)\u001b[0m\n\u001b[0;32m    652\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_field_to_set(field, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fitted_fields)\n\u001b[0;32m    653\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transformers_sequence\u001b[38;5;241m.\u001b[39mappend(transformer)\n\u001b[1;32m--> 654\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    656\u001b[0m output_sdtypes \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mget_output_sdtypes()\n\u001b[0;32m    657\u001b[0m next_transformers \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mget_next_transformers()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\syntheticdata\\lib\\site-packages\\rdt\\transformers\\base.py:277\u001b[0m, in \u001b[0;36mBaseTransformer.transform\u001b[1;34m(self, data, drop)\u001b[0m\n\u001b[0;32m    274\u001b[0m data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    276\u001b[0m columns_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_columns_data(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns)\n\u001b[1;32m--> 277\u001b[0m transformed_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    279\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_columns_to_data(data, transformed_data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_columns)\n\u001b[0;32m    280\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m drop:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\syntheticdata\\lib\\site-packages\\rdt\\transformers\\numerical.py:350\u001b[0m, in \u001b[0;36mGaussianNormalizer._transform\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    348\u001b[0m     transformed[:, \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_copula_transform(transformed[:, \u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m    349\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 350\u001b[0m     transformed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_copula_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransformed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m transformed\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\syntheticdata\\lib\\site-packages\\rdt\\transformers\\numerical.py:333\u001b[0m, in \u001b[0;36mGaussianNormalizer._copula_transform\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_copula_transform\u001b[39m(\u001b[38;5;28mself\u001b[39m, data):\n\u001b[1;32m--> 333\u001b[0m     cdf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_univariate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcdf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    334\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m scipy\u001b[38;5;241m.\u001b[39mstats\u001b[38;5;241m.\u001b[39mnorm\u001b[38;5;241m.\u001b[39mppf(cdf\u001b[38;5;241m.\u001b[39mclip(\u001b[38;5;241m0\u001b[39m \u001b[38;5;241m+\u001b[39m EPSILON, \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m EPSILON))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\syntheticdata\\lib\\site-packages\\copulas\\univariate\\base.py:327\u001b[0m, in \u001b[0;36mUnivariate.cdf\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcdf\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    316\u001b[0m     \u001b[38;5;124;03m\"\"\"Compute the cumulative distribution value for each point in X.\u001b[39;00m\n\u001b[0;32m    317\u001b[0m \n\u001b[0;32m    318\u001b[0m \u001b[38;5;124;03m    Arguments:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;124;03m            Cumulative distribution values for points in X.\u001b[39;00m\n\u001b[0;32m    326\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 327\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcumulative_distribution\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\syntheticdata\\lib\\site-packages\\copulas\\univariate\\base.py:563\u001b[0m, in \u001b[0;36mScipyModel.cumulative_distribution\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    547\u001b[0m \u001b[38;5;124;03m\"\"\"Compute the cumulative distribution value for each point in X.\u001b[39;00m\n\u001b[0;32m    548\u001b[0m \n\u001b[0;32m    549\u001b[0m \u001b[38;5;124;03mArguments:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    560\u001b[0m \u001b[38;5;124;03m        if the model is not fitted.\u001b[39;00m\n\u001b[0;32m    561\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    562\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_fit()\n\u001b[1;32m--> 563\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMODEL_CLASS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcdf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\syntheticdata\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:1997\u001b[0m, in \u001b[0;36mrv_continuous.cdf\u001b[1;34m(self, x, *args, **kwds)\u001b[0m\n\u001b[0;32m   1995\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39many(cond):  \u001b[38;5;66;03m# call only if at least 1 entry\u001b[39;00m\n\u001b[0;32m   1996\u001b[0m     goodargs \u001b[38;5;241m=\u001b[39m argsreduce(cond, \u001b[38;5;241m*\u001b[39m((x,)\u001b[38;5;241m+\u001b[39margs))\n\u001b[1;32m-> 1997\u001b[0m     place(output, cond, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cdf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgoodargs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1998\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1999\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output[()]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\syntheticdata\\lib\\site-packages\\scipy\\stats\\_continuous_distns.py:8180\u001b[0m, in \u001b[0;36mtruncnorm_gen._cdf\u001b[1;34m(self, x, a, b)\u001b[0m\n\u001b[0;32m   8176\u001b[0m it \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mnditer([x, a, b, out], [],\n\u001b[0;32m   8177\u001b[0m                [[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreadonly\u001b[39m\u001b[38;5;124m'\u001b[39m], [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreadonly\u001b[39m\u001b[38;5;124m'\u001b[39m], [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreadonly\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m   8178\u001b[0m                 [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwriteonly\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mallocate\u001b[39m\u001b[38;5;124m'\u001b[39m]])\n\u001b[0;32m   8179\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (_x, _a, _b, _p) \u001b[38;5;129;01min\u001b[39;00m it:\n\u001b[1;32m-> 8180\u001b[0m     _p[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43m_truncnorm_cdf_scalar\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_a\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_b\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   8181\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m it\u001b[38;5;241m.\u001b[39moperands[\u001b[38;5;241m3\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\syntheticdata\\lib\\site-packages\\scipy\\stats\\_continuous_distns.py:7926\u001b[0m, in \u001b[0;36m_truncnorm_cdf_scalar\u001b[1;34m(x, a, b)\u001b[0m\n\u001b[0;32m   7924\u001b[0m delta \u001b[38;5;241m=\u001b[39m _truncnorm_get_delta_scalar(a, b)\n\u001b[0;32m   7925\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m delta \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 7926\u001b[0m     \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcond_inner\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   7927\u001b[0m \u001b[43m             \u001b[49m\u001b[43m(\u001b[49m\u001b[43m_norm_cdf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcond_inner\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m_norm_cdf\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdelta\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   7928\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   7929\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(divide\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mplace\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\syntheticdata\\lib\\site-packages\\numpy\\lib\\function_base.py:1953\u001b[0m, in \u001b[0;36mplace\u001b[1;34m(arr, mask, vals)\u001b[0m\n\u001b[0;32m   1949\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m   1950\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124margument 1 must be numpy.ndarray, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1951\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot \u001b[39m\u001b[38;5;132;01m{name}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mtype\u001b[39m(arr)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m))\n\u001b[1;32m-> 1953\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_insert\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvals\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# load the dataset\n",
    "\n",
    "in_file = ['smoke_detection',\n",
    "         'diabetes',\n",
    "         'cerebral_stroke',\n",
    "         'hr_analysis',\n",
    "         'cervical_cancer',\n",
    "         'census',\n",
    "         'malware_detection',\n",
    "            ### in_file = 'anomaly' ## -- Need to try on Azure. Takes a long time to generate becuase of very high number of fetures \n",
    "         'Titanic',\n",
    "         'insurance',\n",
    "         'House_Rent_Dataset',\n",
    "         'Card_Application_Data',\n",
    "         'creditcard']\n",
    "\n",
    "EPOCH = 10\n",
    "BATCH_SIZE = 50\n",
    "PATH = '../Real Datasets/'\n",
    "SAMPLE_SIZE = 2000\n",
    "\n",
    "for i in range(len(in_file)):\n",
    "    PATH = '../Real Datasets/'\n",
    "    #Concat files and then load\n",
    "    if in_file[i] == 'census':\n",
    "        concat_census_data()\n",
    "        PATH = '../Real Datasets/Adult Census Income Dataset/'\n",
    "    elif in_file[i] =='cervical_cancer':\n",
    "\n",
    "        # Remove the special charecters in the dataset\n",
    "        get_cervical_cancer_data()\n",
    "        PATH = '../Real Datasets/Cervical Cancer/'\n",
    "    elif in_file[i] == 'anomaly':\n",
    "        concat_anomaly_data()\n",
    "        PATH = '../Real Datasets/Anomaly Detection/Participants_Data_WH18/'\n",
    "    elif in_file[i] == 'malware_detection':\n",
    "        PATH = '../Real Datasets/Malware Detection/'\n",
    "    elif in_file[i] == 'hr_analysis':\n",
    "        PATH = '../Real Datasets/HR Analysis/'\n",
    "\n",
    "    real_df = pd.read_csv(PATH + str(in_file[i])+'.csv')\n",
    "    \n",
    "    if len(real_df) < SAMPLE_SIZE:\n",
    "        SAMPLE_SIZE = len(real_df)\n",
    "        #real_df = pd.read_csv(PATH + in_file+'.csv', nrows=SAMPLE_SIZE)\n",
    "    out_path1 = '../Synthetic Datasets/sdv_gauss/sdv_gauss_'+in_file[i]+'.csv'\n",
    "    out_path2 = '../Synthetic Datasets/sdv_ctgan/sdv_ctgan_'+in_file[i]+'.csv'\n",
    "    out_path3 = '../Synthetic Datasets/sdv_copula/sdv_copula_'+in_file[i]+'.csv'\n",
    "    out_path4 = '../Synthetic Datasets/sdv_tvae/sdv_tvae_'+in_file[i]+'.csv'\n",
    "    generate_gaussian(in_file[i])\n",
    "    generate_ctgan(in_file[i])\n",
    "    generate_copula_gan(in_file[i])\n",
    "    generate_tvae(in_file[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de6596b",
   "metadata": {},
   "source": [
    "# Observation\n",
    "The Gaussian generator did not generate any data for outliers. When the data size is large and the minority class is small, it tends to ignore the minority class completely.In Titanic dataset, Age is an outlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3709a39e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
